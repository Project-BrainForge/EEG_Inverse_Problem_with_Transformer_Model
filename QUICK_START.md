# âš¡ Quick Start Guide

## ğŸ¯ What You Have

A complete **Transformer-based EEG source localization system** that:

- Maps EEG signals (500Ã—75) â†’ Brain source activity (500Ã—994)
- Uses state-of-the-art Transformer architecture
- Includes training, evaluation, and inference scripts
- Has comprehensive documentation

---

## ğŸš€ Get Started in 3 Steps

### Step 1: Install (2 minutes)

```bash
# Navigate to project
cd /Users/pasindusankalpa/Documents/dataset_deepSIF/transformer_model

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install PyTorch (choose based on your system)
# For CPU (macOS/Linux):
pip install torch torchvision torchaudio

# Install other dependencies
pip install -r requirements.txt

# Verify installation
python test_setup.py
```

### Step 2: Train (depends on data size)

```bash
cd src
python train.py --config ../configs/config.yaml
```

### Step 3: Evaluate

```bash
cd src
python evaluate.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --split val \
    --visualize
```

---

## ğŸ“Š Monitor Training

Open a new terminal:

```bash
cd /Users/pasindusankalpa/Documents/dataset_deepSIF/transformer_model
source venv/bin/activate
tensorboard --logdir logs
```

Then open: http://localhost:6006

---

## ğŸ“ What's Where

```
transformer_model/
â”œâ”€â”€ ğŸ“– README.md              â† Start here
â”œâ”€â”€ ğŸ“– QUICK_START.md         â† This file
â”œâ”€â”€ ğŸ“– INSTALL.md             â† Detailed installation
â”œâ”€â”€ ğŸ“– PROJECT_SUMMARY.md     â† Complete overview
â”œâ”€â”€ ğŸ“– ARCHITECTURE.md        â† Model architecture
â”œâ”€â”€ ğŸ“– WORKFLOW.md            â† Step-by-step workflows
â”‚
â”œâ”€â”€ âš™ï¸  configs/config.yaml    â† Configure everything here
â”œâ”€â”€ ğŸ“¦ requirements.txt       â† Dependencies
â”œâ”€â”€ ğŸ§ª test_setup.py          â† Verify installation
â”‚
â”œâ”€â”€ ğŸ“‚ src/                   â† Source code
â”‚   â”œâ”€â”€ models/transformer.py  (Model architecture)
â”‚   â”œâ”€â”€ data/dataset.py        (Data loading)
â”‚   â”œâ”€â”€ utils/helpers.py       (Utilities)
â”‚   â”œâ”€â”€ train.py               (Training script)
â”‚   â”œâ”€â”€ evaluate.py            (Evaluation script)
â”‚   â””â”€â”€ inference.py           (Inference script)
â”‚
â”œâ”€â”€ ğŸ“‚ dataset_with_label/    â† Your data (10 samples)
â”œâ”€â”€ ğŸ“‚ checkpoints/           â† Saved models (after training)
â”œâ”€â”€ ğŸ“‚ logs/                  â† TensorBoard logs (after training)
â””â”€â”€ ğŸ“‚ results/               â† Evaluation results (after eval)
```

---

## âš™ï¸ Configuration

Edit `configs/config.yaml`:

```yaml
# Quick tweaks for common scenarios:

# ğŸ¯ For better accuracy (slower training):
model:
  d_model: 512
  num_layers: 8

# âš¡ For faster training (may reduce accuracy):
model:
  d_model: 128
  num_layers: 4
batch_size: 16

# ğŸ›¡ï¸ If overfitting (val loss > train loss):
model:
  dropout: 0.3
optimizer:
  weight_decay: 0.1

# ğŸ”§ If underfitting (both losses high):
optimizer:
  lr: 0.0005  # Increase learning rate
num_epochs: 300  # Train longer
```

---

## ğŸ¯ Common Tasks

### Train the model

```bash
cd src
python train.py --config ../configs/config.yaml
```

### Resume training from checkpoint

```bash
cd src
python train.py \
    --config ../configs/config.yaml \
    --resume ../checkpoints/checkpoint_epoch_50.pth
```

### Evaluate the model

```bash
cd src
python evaluate.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --split val
```

### Make predictions (single file)

```bash
cd src
python inference.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --input ../dataset_with_label/sample_00000.mat \
    --output ../results/prediction.mat
```

### Make predictions (batch)

```bash
cd src
python inference.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --input ../dataset_with_label \
    --output ../results/predictions \
    --batch
```

---

## ğŸ› Troubleshooting

### "No module named 'torch'"

```bash
pip install torch torchvision torchaudio
```

### "CUDA out of memory"

Reduce batch size in `configs/config.yaml`:

```yaml
batch_size: 4 # or smaller
```

### Training is slow

- Use GPU if available
- Increase batch_size (if memory allows)
- Reduce model size (d_model, num_layers)

### Model not learning

- Check learning rate (try 1e-4 to 1e-3)
- Train longer (increase num_epochs)
- Check TensorBoard for issues
- Verify data is normalized

### Import errors

Make sure you're in the right directory:

```bash
cd src  # Must be in src directory
python train.py --config ../configs/config.yaml
```

---

## ğŸ“š Documentation Overview

| Document               | Purpose                | When to Read          |
| ---------------------- | ---------------------- | --------------------- |
| **QUICK_START.md**     | Get started fast       | First                 |
| **README.md**          | Main documentation     | After installation    |
| **INSTALL.md**         | Installation help      | If setup issues       |
| **PROJECT_SUMMARY.md** | Complete overview      | To understand project |
| **ARCHITECTURE.md**    | Model details          | To understand model   |
| **WORKFLOW.md**        | Step-by-step workflows | During development    |

---

## ğŸ“ Understanding Your Model

### Input

- **EEG data**: 500 time points Ã— 75 channels
- **Format**: .mat file with 'eeg_data' field
- **Shape**: (500, 75)

### Output

- **Source activity**: 500 time points Ã— 994 brain regions
- **Format**: .mat file with 'source_data' field
- **Shape**: (500, 994)

### Model

- **Architecture**: Transformer encoder
- **Parameters**: ~8.5M (default config)
- **Training**: Supervised learning with MSE loss
- **Metrics**: MSE, MAE, Correlation, RÂ²

---

## ğŸ“Š Expected Performance

With default settings and adequate training data:

| Metric          | Target Value |
| --------------- | ------------ |
| Training Loss   | < 0.1        |
| Validation Loss | < 0.15       |
| Correlation     | > 0.85       |
| RÂ² Score        | > 0.70       |

**Note**: You have 10 samples. For better results, add more data!

---

## ğŸ” What Happens During Training

```
1. Load dataset â†’ Split train/val (8/2 with 10 samples)
2. Create model â†’ Initialize ~8.5M parameters
3. For each epoch:
   â”œâ”€ Forward pass: EEG â†’ Model â†’ Predictions
   â”œâ”€ Compute loss: MSE(predictions, ground_truth)
   â”œâ”€ Backward pass: Compute gradients
   â”œâ”€ Update weights: Optimizer step
   â””â”€ Validate: Check performance on validation set
4. Save best model based on validation loss
5. Early stopping if no improvement for 30 epochs
```

---

## âš¡ Performance Tips

### To improve accuracy:

- Add more training data (most important!)
- Increase model size (d_model, num_layers)
- Train longer (more epochs)
- Tune hyperparameters

### To speed up training:

- Use GPU (if available)
- Increase batch size
- Reduce model size
- Use fewer epochs

### To reduce overfitting:

- Add more data
- Increase dropout
- Increase weight_decay
- Use data augmentation

---

## ğŸ¯ Next Steps

1. âœ… **Install dependencies**

   ```bash
   pip install -r requirements.txt
   python test_setup.py
   ```

2. âœ… **Start training**

   ```bash
   cd src
   python train.py --config ../configs/config.yaml
   ```

3. âœ… **Monitor progress**

   ```bash
   tensorboard --logdir logs
   ```

4. âœ… **Evaluate results**

   ```bash
   python evaluate.py --config ../configs/config.yaml --checkpoint ../checkpoints/best_model.pth
   ```

5. âœ… **Make predictions**
   ```bash
   python inference.py --config ../configs/config.yaml --checkpoint ../checkpoints/best_model.pth --input ../dataset_with_label/sample_00000.mat
   ```

---

## ğŸ’¡ Tips for Success

1. **Start small**: Use default config first
2. **Monitor training**: Always use TensorBoard
3. **Check validation**: Watch for overfitting
4. **Save checkpoints**: Don't lose trained models
5. **Document changes**: Keep track of experiments
6. **Add more data**: More data = better results!

---

## ğŸ†˜ Need Help?

1. **Installation issues** â†’ Read `INSTALL.md`
2. **Understanding code** â†’ Read `ARCHITECTURE.md`
3. **Step-by-step guide** â†’ Read `WORKFLOW.md`
4. **Complete overview** â†’ Read `PROJECT_SUMMARY.md`
5. **General usage** â†’ Read `README.md`

---

## âœ¨ You're Ready!

Your transformer model is ready to train. The complete implementation is production-ready with:

âœ… Professional code structure  
âœ… Comprehensive documentation  
âœ… Training pipeline  
âœ… Evaluation tools  
âœ… Inference scripts  
âœ… Configuration management  
âœ… Monitoring with TensorBoard

**Start training now:**

```bash
cd src && python train.py --config ../configs/config.yaml
```

Good luck! ğŸš€ğŸ§ 
