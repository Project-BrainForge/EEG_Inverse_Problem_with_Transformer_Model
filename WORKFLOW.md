# Workflow Guide: From Installation to Deployment

## ğŸ“‹ Table of Contents
1. [Installation Workflow](#installation-workflow)
2. [Training Workflow](#training-workflow)
3. [Evaluation Workflow](#evaluation-workflow)
4. [Inference Workflow](#inference-workflow)
5. [Customization Workflow](#customization-workflow)

---

## ğŸ”§ Installation Workflow

```
START
  â”‚
  â”œâ”€â†’ Step 1: Create Virtual Environment
  â”‚   $ python3 -m venv venv
  â”‚   $ source venv/bin/activate
  â”‚
  â”œâ”€â†’ Step 2: Install PyTorch
  â”‚   $ pip install torch torchvision torchaudio
  â”‚
  â”œâ”€â†’ Step 3: Install Dependencies
  â”‚   $ pip install -r requirements.txt
  â”‚
  â”œâ”€â†’ Step 4: Verify Installation
  â”‚   $ python test_setup.py
  â”‚
  â””â”€â†’ âœ… Ready to Train!
```

### Quick Installation (Automated)
```bash
./quick_start.sh
```

---

## ğŸš€ Training Workflow

### Standard Training Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARE DATA                                         â”‚
â”‚    â€¢ Place .mat files in dataset_with_label/           â”‚
â”‚    â€¢ Ensure format: eeg_data (500,75)                  â”‚
â”‚                    source_data (500,994)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONFIGURE MODEL                                      â”‚
â”‚    â€¢ Edit configs/config.yaml                          â”‚
â”‚    â€¢ Set hyperparameters (d_model, layers, etc.)      â”‚
â”‚    â€¢ Set training params (lr, batch_size, epochs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. START TRAINING                                       â”‚
â”‚    $ cd src                                            â”‚
â”‚    $ python train.py --config ../configs/config.yaml  â”‚
â”‚                                                        â”‚
â”‚    What happens:                                       â”‚
â”‚    â”œâ”€ Load dataset â†’ split train/val                  â”‚
â”‚    â”œâ”€ Create model â†’ initialize weights               â”‚
â”‚    â”œâ”€ Setup optimizer & scheduler                     â”‚
â”‚    â””â”€ Start training loop                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MONITOR TRAINING (parallel terminal)                â”‚
â”‚    $ tensorboard --logdir logs                         â”‚
â”‚    â†’ Open http://localhost:6006                        â”‚
â”‚                                                        â”‚
â”‚    Watch:                                              â”‚
â”‚    â”œâ”€ Training loss (should decrease)                 â”‚
â”‚    â”œâ”€ Validation loss (should decrease)               â”‚
â”‚    â”œâ”€ Correlation (should increase)                   â”‚
â”‚    â””â”€ Learning rate (should adjust automatically)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. TRAINING COMPLETES                                   â”‚
â”‚    Outputs:                                            â”‚
â”‚    â”œâ”€ checkpoints/best_model.pth (best val loss)      â”‚
â”‚    â”œâ”€ checkpoints/checkpoint_epoch_*.pth (each epoch) â”‚
â”‚    â””â”€ logs/ (TensorBoard logs)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
              âœ… Model Trained!
```

### Training Commands

**Basic training:**
```bash
cd src
python train.py --config ../configs/config.yaml
```

**With custom data directory:**
```bash
python train.py --config ../configs/config.yaml --data_dir /path/to/data
```

**Resume from checkpoint:**
```bash
python train.py --config ../configs/config.yaml --resume ../checkpoints/checkpoint_epoch_50.pth
```

### What to Expect During Training

```
Epoch [1/200] Batch [0/8] Loss: 1.234567 Time: 0.123s
Epoch [1/200] Batch [10/8] Loss: 0.987654 Time: 0.115s

Validation - Epoch [1/200]
  Loss: 0.876543
  MAE: 0.765432
  Correlation: 0.7234

Checkpoint saved to checkpoints/checkpoint_epoch_1.pth
Best model saved to checkpoints/best_model.pth

Epoch [2/200] Batch [0/8] Loss: 0.856432 Time: 0.112s
...
```

---

## ğŸ“Š Evaluation Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. SELECT CHECKPOINT                                    â”‚
â”‚    â€¢ Usually: checkpoints/best_model.pth               â”‚
â”‚    â€¢ Or specific epoch: checkpoint_epoch_N.pth         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RUN EVALUATION                                       â”‚
â”‚    $ cd src                                            â”‚
â”‚    $ python evaluate.py \                              â”‚
â”‚        --config ../configs/config.yaml \               â”‚
â”‚        --checkpoint ../checkpoints/best_model.pth \    â”‚
â”‚        --split val                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. MODEL EVALUATION                                     â”‚
â”‚    Process:                                            â”‚
â”‚    â”œâ”€ Load trained model                              â”‚
â”‚    â”œâ”€ Load validation data                            â”‚
â”‚    â”œâ”€ Run inference on all samples                    â”‚
â”‚    â”œâ”€ Compute metrics (MSE, MAE, Corr, RÂ²)           â”‚
â”‚    â””â”€ Generate visualizations                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. RESULTS GENERATED                                    â”‚
â”‚    Outputs:                                            â”‚
â”‚    â”œâ”€ results/evaluation_val.npz (all predictions)    â”‚
â”‚    â”œâ”€ results/metrics_val.txt (metrics text)          â”‚
â”‚    â””â”€ results/visualization_*.png (if --visualize)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ANALYZE RESULTS                                      â”‚
â”‚    Check:                                              â”‚
â”‚    â”œâ”€ Correlation > 0.85? âœ… Good                     â”‚
â”‚    â”œâ”€ RÂ² > 0.70? âœ… Good                              â”‚
â”‚    â”œâ”€ MAE acceptable? (domain-specific)               â”‚
â”‚    â””â”€ Visual inspection: predictions match targets?   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         Satisfied with results?
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
      YES                NO
        â”‚                 â”‚
        â–¼                 â–¼
  Deploy Model    Improve Model
                  (see Customization)
```

### Evaluation Commands

**Basic evaluation:**
```bash
cd src
python evaluate.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --split val
```

**With visualization:**
```bash
python evaluate.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --split val \
    --visualize \
    --sample_idx 0
```

**Evaluate on training set:**
```bash
python evaluate.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --split train
```

### Expected Output

```
============================================================
Evaluating on val set (2 samples)
============================================================

Processed 1/1 batches

============================================================
Evaluation Results on val set:
============================================================
  MSE:             0.123456
  MAE:             0.234567
  RMSE:            0.345678
  Correlation:     0.8765
  RÂ²:              0.7654
  Relative Error:  0.1234
============================================================

Results saved to results/evaluation_val.npz
Metrics saved to results/metrics_val.txt
```

---

## ğŸ¯ Inference Workflow

### Single File Inference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARE INPUT                                        â”‚
â”‚    â€¢ Single .mat file with 'eeg_data' (500, 75)        â”‚
â”‚    â€¢ Example: sample_00000.mat                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RUN INFERENCE                                        â”‚
â”‚    $ cd src                                            â”‚
â”‚    $ python inference.py \                             â”‚
â”‚        --config ../configs/config.yaml \               â”‚
â”‚        --checkpoint ../checkpoints/best_model.pth \    â”‚
â”‚        --input ../dataset_with_label/sample_00000.mat \â”‚
â”‚        --output ../results/prediction.mat              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. PREDICTION GENERATED                                 â”‚
â”‚    Output file: prediction.mat                         â”‚
â”‚    Contains:                                           â”‚
â”‚    â”œâ”€ source_data_predicted (500, 994)                â”‚
â”‚    â”œâ”€ eeg_data (original input)                       â”‚
â”‚    â””â”€ source_data_true (if available)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
              âœ… Done!
```

### Batch Inference

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PREPARE DIRECTORY                                    â”‚
â”‚    â€¢ Multiple .mat files in directory                  â”‚
â”‚    â€¢ Each with 'eeg_data' field                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RUN BATCH INFERENCE                                  â”‚
â”‚    $ cd src                                            â”‚
â”‚    $ python inference.py \                             â”‚
â”‚        --config ../configs/config.yaml \               â”‚
â”‚        --checkpoint ../checkpoints/best_model.pth \    â”‚
â”‚        --input ../dataset_with_label \                 â”‚
â”‚        --output ../results/predictions \               â”‚
â”‚        --batch                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BATCH PROCESSING                                     â”‚
â”‚    For each file:                                      â”‚
â”‚    â”œâ”€ Load EEG data                                    â”‚
â”‚    â”œâ”€ Normalize using training stats                  â”‚
â”‚    â”œâ”€ Run model inference                             â”‚
â”‚    â”œâ”€ Denormalize predictions                         â”‚
â”‚    â””â”€ Save to output directory                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ALL PREDICTIONS SAVED                                â”‚
â”‚    results/predictions/                                â”‚
â”‚    â”œâ”€ predicted_sample_00000.mat                      â”‚
â”‚    â”œâ”€ predicted_sample_00001.mat                      â”‚
â”‚    â””â”€ ...                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
              âœ… Batch Complete!
```

### Inference Commands

**Single file:**
```bash
cd src
python inference.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --input ../dataset_with_label/sample_00000.mat \
    --output ../results/prediction.mat
```

**Batch processing:**
```bash
python inference.py \
    --config ../configs/config.yaml \
    --checkpoint ../checkpoints/best_model.pth \
    --input ../dataset_with_label \
    --output ../results/predictions \
    --batch
```

---

## ğŸ”¨ Customization Workflow

### Improving Model Performance

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model not performing well?                             â”‚
â”‚ Follow this decision tree:                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         Is training loss high?
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
      YES                NO
        â”‚                 â”‚
        â”‚                 â””â”€â†’ Model underfitting
        â”‚                     â”œâ”€ Increase model size
        â”‚                     â”‚   (d_model, num_layers)
        â”‚                     â”œâ”€ Train longer
        â”‚                     â””â”€ Lower learning rate
        â”‚
        â–¼
  Is validation loss >> training loss?
        â”‚
        â”œâ”€ YES â†’ Model overfitting
        â”‚         â”œâ”€ Add more data
        â”‚         â”œâ”€ Increase dropout
        â”‚         â”œâ”€ Increase weight_decay
        â”‚         â””â”€ Reduce model size
        â”‚
        â””â”€ NO â†’ Need better architecture
                  â”œâ”€ Try encoder-decoder
                  â”œâ”€ Adjust num_layers
                  â””â”€ Tune hyperparameters
```

### Hyperparameter Tuning Guide

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. BASELINE EXPERIMENT                                  â”‚
â”‚    â€¢ Run with default config                           â”‚
â”‚    â€¢ Record results                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TUNE LEARNING RATE                                   â”‚
â”‚    Try: [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]                â”‚
â”‚    Pick the one with best val loss                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. TUNE MODEL SIZE                                      â”‚
â”‚    d_model: [128, 256, 512]                           â”‚
â”‚    num_layers: [4, 6, 8]                              â”‚
â”‚    Balance performance vs. speed                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. TUNE REGULARIZATION                                  â”‚
â”‚    dropout: [0.0, 0.1, 0.2, 0.3]                      â”‚
â”‚    weight_decay: [0.0, 0.01, 0.05, 0.1]               â”‚
â”‚    Find sweet spot                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. FINE-TUNE OTHER PARAMS                               â”‚
â”‚    â€¢ batch_size                                        â”‚
â”‚    â€¢ num_heads                                         â”‚
â”‚    â€¢ dim_feedforward                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
              âœ… Optimized!
```

### Configuration Examples

**Small/Fast Model:**
```yaml
model:
  d_model: 128
  num_layers: 4
  dim_feedforward: 512
  nhead: 4
batch_size: 16
```

**Large/Accurate Model:**
```yaml
model:
  d_model: 512
  num_layers: 8
  dim_feedforward: 2048
  nhead: 8
batch_size: 4
```

**Regularized Model (prevent overfitting):**
```yaml
model:
  dropout: 0.3
optimizer:
  weight_decay: 0.1
```

---

## ğŸ“ˆ Complete ML Pipeline

```
DATA PREPARATION
     â†“
DATA LOADING & PREPROCESSING
     â†“
MODEL ARCHITECTURE DESIGN
     â†“
TRAINING
     â†“
MONITORING (TensorBoard)
     â†“
EVALUATION
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Good Results?  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
  NO â”‚ YES
     â”‚  â”‚
     â”‚  â””â†’ DEPLOYMENT
     â”‚      â†“
     â”‚   INFERENCE
     â”‚      â†“
     â”‚   PRODUCTION
     â”‚
     â””â†’ HYPERPARAMETER TUNING
         â†“
      RE-TRAINING
         â†“
      (back to TRAINING)
```

---

## ğŸš€ Production Deployment Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. EXPORT BEST MODEL                                    â”‚
â”‚    â€¢ Identify best checkpoint                          â”‚
â”‚    â€¢ Copy to deployment directory                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. OPTIMIZE MODEL (optional)                            â”‚
â”‚    â€¢ TorchScript compilation                           â”‚
â”‚    â€¢ ONNX export                                       â”‚
â”‚    â€¢ Quantization                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CREATE INFERENCE SERVICE                             â”‚
â”‚    â€¢ Flask/FastAPI REST API                            â”‚
â”‚    â€¢ gRPC service                                      â”‚
â”‚    â€¢ Batch processing script                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. DEPLOY                                               â”‚
â”‚    â€¢ Docker container                                  â”‚
â”‚    â€¢ Cloud service (AWS, GCP, Azure)                  â”‚
â”‚    â€¢ On-premise server                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
              âœ… In Production!
```

---

## ğŸ’¡ Quick Reference Commands

### Installation
```bash
python3 -m venv venv && source venv/bin/activate
pip install torch && pip install -r requirements.txt
python test_setup.py
```

### Training
```bash
cd src && python train.py --config ../configs/config.yaml
```

### Monitoring
```bash
tensorboard --logdir logs
```

### Evaluation
```bash
cd src && python evaluate.py --config ../configs/config.yaml --checkpoint ../checkpoints/best_model.pth --split val
```

### Inference
```bash
cd src && python inference.py --config ../configs/config.yaml --checkpoint ../checkpoints/best_model.pth --input ../dataset_with_label/sample_00000.mat --output ../results/prediction.mat
```

---

## ğŸ“Š Success Checklist

### Before Training
- [ ] Dependencies installed
- [ ] test_setup.py passes
- [ ] Dataset in correct location
- [ ] Config file customized

### During Training
- [ ] TensorBoard running
- [ ] Training loss decreasing
- [ ] Validation loss decreasing
- [ ] No NaN values

### After Training
- [ ] Checkpoints saved
- [ ] Best model identified
- [ ] Evaluation metrics computed
- [ ] Results visualized

### Deployment Ready
- [ ] Model performance acceptable
- [ ] Inference script tested
- [ ] Documentation complete
- [ ] Production plan ready

---

You're all set! Follow these workflows to go from installation to deployment. ğŸš€

